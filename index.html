<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Growing a Brain with Sparsity-Inducing Generation for Continual Learning</title>
  <link rel="icon" type="image/x-icon" href="static/images/VLLAB-02.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <!-- Title -->
          <h1 class="title is-1 publication-title">
            Growing a Brain with Sparsity-Inducing Generation for Continual Learning
          </h1>

          <!-- Authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jin0316.github.io/HyundongJin.io/" target="_blank"><strong>Hyundong Jin</strong></a><sup>1</sup>,
            </span>
            <span class="author-block">
              <strong>Gyeong-hyeon Kim</strong><sup>1</sup>,
            </span>
            <span class="author-block">
              <strong>Chanho Ahn</strong><sup>2*</sup>,
            </span>
            <span class="author-block">
              <a href="https://vllab.cau.ac.kr/members/professor/" target="_blank"><strong>Eunwoo Kim</strong></a><sup>1</sup>
            </span>
          </div>

          <!-- Affiliations -->
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>School of Computer Science and Engineering, Chung-Ang University</span><br>
            <span class="author-block"><sup>2</sup>Samsung Advanced Institute of Technology (SAIT)</span><br>
            <span class="author-block"><sup>*</sup>*This work was done independently, without any support from SAIT.</span>
          </div>

          <!-- Emails -->
          <div class="is-size-6 publication-authors">
            <span class="author-block">{jude0316, leonardkkh, eunwoo}@cau.ac.kr</span>,
            <span class="author-block">chanho.ahn@samsung.com</span>
          </div>

          <!-- Conference -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">ICCV 2023</span>
          </div>

          <!-- Links -->
          <div class="column has-text-centered">
            <div class="publication-links">

              <!-- Paper -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.pdf"
                  target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Code -->
              <span class="link-block">
                <a href="https://github.com/Jin0316/GrowBrain"
                  target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

  

<!-- Paper poster -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
        <img src="static/images/main.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle subtitle-justified">
          <p>
          An overview of GrowBrain, which evolves old knowledge through sparsity-inducing parameter generation. 
            For each task, a hypernetwork generates a task- and layer-conditioned sparse parameter set that transforms the previously learned weights, enabling adaptive reuse of past knowledge without interference.
          </p>
        </h2>
      </div>
    </div>
  </section>
<!--End paper poster -->
  
<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Deep neural networks suffer from catastrophic forgetting in continual learning, where they tend to lose information about previously learned tasks when optimizing a new incoming task. 
            Recent strategies isolate the important parameters for previous tasks to retain old knowledge while learning the new task. 
            However, using the fixed old knowledge might act as an obstacle to capturing novel representations. 
            To overcome this limitation, we propose a framework that evolves the previously allocated parameters by absorbing the knowledge of the new task. 
            The approach performs under two different networks. 
            The base network learns knowledge of sequential tasks, and the sparsity-inducing hypernetwork generates parameters for each time step for evolving old knowledge. 
            The generated parameters transform old parameters of the base network to reflect the new knowledge. 
            We design the hypernetwork to generate sparse parameters conditional to the task-specific information and the structural information of the base network. 
            We evaluate the proposed approach on class-incremental and taskincremental learning scenarios for image classification and video action recognition tasks. 
            Experimental results show that the proposed method consistently outperforms a large variety of continual learning approaches for those scenarios by evolving old knowledge.

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- Paper poster -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">

      <!-- 설명 텍스트 -->
      <div class="content has-text-justified">
        <p>
          <strong>Motivation:</strong><br>
          In continual learning, parameter isolation methods prevent forgetting by freezing disjoint parameter subsets for each task. 
          However, this strategy assumes that old parameters are always reusable, which limits their adaptability to new tasks. 
          We argue that merely reusing fixed parameters from prior tasks is insufficient, especially when tasks exhibit distributional shifts. 
          The core question we raise is: can old knowledge be evolved rather than statically preserved to better support future learning?
        </p>

        <p>
          <strong>Proposed Method:</strong><br>
          We propose GrowBrain, a novel continual learning framework that evolves old knowledge through sparsity-inducing parameter generation. 
          Our method consists of a base network and a hypernetwork. 
          The hypernetwork receives a task token and layer embeddings and generates a transformed parameter set for each new task. 
          By introducing a sparsity loss based on loss difference with/without each parameter, GrowBrain selectively generates only essential updates to the parameter space, avoiding redundancy. 
          This results in an evolved, task-adaptive version of previously learned knowledge. Additionally, a reconstruction loss encourages consistency across tasks.
        </p>

        <p>
          <strong>Experimental Results:</strong><br>
          We evaluate GrowBrain on both image classification and video action recognition benchmarks, including ImageNet, CUBS, Stanford Cars, Flowers, Wikiart, Sketch, ActivityNet, and UCF-101. 
          GrowBrain consistently outperforms strong continual learning baselines by achieving higher accuracy while maintaining compact parameter growth. 
          Ablation studies confirm that sparsity-inducing generation and task-layer–conditioned parameter evolution are essential for preventing forgetting and enabling efficient adaptation.
        </p>
      </div>

      <!-- Toggle 가능한 이미지 캐러셀 부분 -->
      <div id="results-carousel" class="carousel results-carousel mt-5">
        <div class="item has-text-centered">
          <img src="static/images/results_1.png" alt="Result 1">
          <h2 class="subtitle is-6 has-text-centered mt-2">
            Comparison of classification accuracy (Acc, %) and parameter usage (Param, M) on task-incremental learning with large-scale and diverse datasets: ImageNet, CUBS, Stanford Cars, Flowers, Wikiart, and Sketch. 
            H<sup>2</sup> achieves superior accuracy with significantly fewer parameters than existing methods.
          </h2>
        </div>
        <div class="item has-text-centered">
          <img src="static/images/results_2.png" alt="Result 2">
          <h2 class="subtitle is-6 has-text-centered mt-2">
            Task-incremental and class-incremental results on Split MNIST and Split CIFAR-10. 
            H<sup>2</sup> consistently outperforms strong baselines and approaches joint training performance without accessing previous task data.
          </h2>
        </div>
        <div class="item has-text-centered">
          <img src="static/images/results_3.png" alt="Result 3">
          <h2 class="subtitle is-6 has-text-centered mt-2">
            Ablation study results on Split CIFAR-10 under both task- and class-incremental scenarios. 
            The effectiveness of the model search, sensitivity-based parameter selection, and contrastive loss is validated, with additional comparisons on parameter count, FLOPs, and memory usage for binary masks.
          </h2>
        </div>
      </div>

    </div>
  </div>
</section>
<!--End paper poster -->



<!-- Paper poster 
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
        <img src="static/images/poster.png">
      </div>
    </div>
</section>
<!--End paper poster -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@inproceedings{jin2022helpful,
  title={Helpful or harmful: Inter-task association in continual learning},
  author={Jin, Hyundong and Kim, Eunwoo},
  booktitle={European conference on computer vision},
  pages={519--535},
  year={2022},
  organization={Springer}
}
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->

<!--
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>
-->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
